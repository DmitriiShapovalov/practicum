{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт всех необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dshap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dshap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dshap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dshap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#загружаем библиотеки для работы с данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#загружаем библиотеку для отображения времени выполнения ячейки и времени выполнения кода\n",
    "import time\n",
    "\n",
    "#загружаем библиотеку для корректной загрузки датасетов\n",
    "import os\n",
    "\n",
    "#загружаем библиотеку для проверки корректности url ссылки\n",
    "import requests\n",
    "\n",
    "#загружаем библиотеки для управления уведомлениями\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "#загружаем классы для визуализации\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#загружаем класс для расчета TF-IDF и мешка слов\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#загрузка модуля и словарей для лематизации текста на английском языке\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#загружаем модули и словарь для добавления POS-тегов\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import pos_tag\n",
    "\n",
    "#загрузка библиотеки модуля для обработки стоп-слов и архива со стоп-словами \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#загрузка библиотеки для создания регулярных выражений\n",
    "import re\n",
    "\n",
    "# загружаем классы для подготовки данных\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#загружаем модули для создания piepline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# загружаем нужные модели\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#загружаем инструменты для подбора гиперпараметров\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from optuna.integration import OptunaSearchCV\n",
    "from optuna import distributions\n",
    "import optuna\n",
    "\n",
    "# загружаем функции для работы с метриками\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#загружаем класс для устранения дисбаланса посредством андерсемплинга\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#загружаем библиотеки для работы с моделью типа BERT\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "#загружаем библиотеку для отображения прогресса при делении задачи на батчи\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявляем также константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем файл датасета, создаем датафрейм, выводим первые 15 строк и основную информацию для ознакомления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic\n",
       "0   Explanation\\nWhy the edits made under my usern...      0\n",
       "1   D'aww! He matches this background colour I'm s...      0\n",
       "2   Hey man, I'm really not trying to edit war. It...      0\n",
       "3   \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4   You, sir, are my hero. Any chance you remember...      0\n",
       "5   \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7   Your vandalism to the Matt Shirvington article...      0\n",
       "8   Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9   alignment on this subject and which are contra...      0\n",
       "10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0\n",
       "11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0\n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "13  Before you start throwing accusations and warn...      0\n",
       "14  Oh, and the girl above started her arguments w...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#проверяем существование указанной дирректории и в случае возврата True загружаем датасет в переменную, указав верные разделители\n",
    "pth1 = '/datasets/toxic_comments.csv'\n",
    "pth2 = 'https://...../toxic_comments.csv' #полная ссылка скрыта ввиду NDA\n",
    "pth3 = 'toxic_comments.csv'\n",
    "if os.path.exists(pth1):\n",
    "    data_main = pd.read_csv(pth1, sep=',', decimal = '.', index_col = [0])\n",
    "#добавляем проверку корректности url ссылки при помощи requests.get(url) и проверки status_code == 200\n",
    "elif requests.get(pth2).status_code == 200:\n",
    "    data_main = pd.read_csv(pth2, sep=',', decimal = '.', index_col = [0])\n",
    "if os.path.exists(pth3):\n",
    "    data_main = pd.read_csv(pth3, sep=',', decimal = '.', index_col = [0])\n",
    "else:\n",
    "    print('Something is wrong')\n",
    "\n",
    "#выводим первые 15 строк и основную информацию датафрейма    \n",
    "display(data_main.head(15))\n",
    "data_main.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Созданный датафрейм:**\n",
    "- имеет размерность 159292 строки\n",
    "- пропущены порядковые индексы строк\n",
    "- не имеет явных пропусков\n",
    "- столбцы имеют корректные типы данных\n",
    "- названия столбцов приведены к змеиному \"регистру\"\n",
    "- при первичном ознакомлении неявные дубликаты не выделяются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как датасет состоит всего из двух столбцов, то выделять основные разделы по предобработке данных не будем, а основное опишем в одном небольшом пункте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще раз проверим отсутствие явных пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_main.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим датасет на наличие явных дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_main.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в некоторых строках есть пропущенные индексы, то обновим все индексы в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_main = data_main.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение целевого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    143106\n",
       "1     16186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_main['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Токсичных комментариев чуть больше 10% от общего количества, явный дисбаланс, при разбиении на выборки добавим параметр `stratify`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На этапе предобработки данных:**\n",
    "- проверено, что в датасете отсутствуют явные пропуски\n",
    "- проверено наличие явных дубликатов\n",
    "- из-за пропущенных индексов были обновлены индексы всего датасета\n",
    "- выявлен сильный дисбаланс классов в целевом признаке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем исследовании попробуем получить прогнозные значения целевого признака при помощи нескольких подходов:\n",
    "- при ручной токенизации, лематизации, фильтрации от стоп-слов, создании частотных признаков TF-IDF, признаков на основе мешка слов и N-грамм, дальнешего обучения на моделях логистической регрессии, дерева решений и CatBoostClassisfier(). Так как модели будут обучаться долго на таком наборе данных, особенно долго обучается модель CatBoostClassisfier(), то в качестве базовой модели возьмем  LogisticRegression(), для модели DecisionTreeClassifier() для оптимизации подбора лучших гиперпараметров будем использовать OptunaSearchCV(), а у модели CatBoostClassifier() возьмем стандартный набор гиперпараметров(). Также попробуем улучшить метрику, применив андерсемплинг тренировочной выборки для устранения дисбаланса классов.\n",
    "- второй подход будет заключаться в использовании предобученной модели BERT (токенизатора и модели для получения эмбеддингов), обработки текста при помощи этих моделей при помощи GPU  для ускорения расчетов и дальнейшей классификации при помощи тех же моделей LogisticRegression() и CatBoostClassisfier().\n",
    "- основная метрика качества - F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мешок слов, TF-IDF и N-граммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Очистка и лематизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для лематизации строк текста будем использовать библиотеку `WordNetLemmatizer()`, входящую в состав библиотеки `NLTK` и работающей с текстом на английском языке. Для обработки всех строк текста напишем функцию для лематизации текста, включающую добавление POS-тегов, показывающих принадлежность каждого слова к определенной части речи. Также напишем функцию для очистки предложений от ненужных символов, пробелов и переведения всего текста в нижний регистр. Применим эти две функции ко всему столбцу `text` с отображением прогресса через `progress_apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    \"\"\" Функция очистки текста: удаление всех лишних символов, удаление лишних пробелов и перевод в нижний регистр\"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    text = \" \".join(text.split())\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def pos_tagger(nltk_tag):\n",
    "    \"\"\"Функция для определения основных POS-тегов\"\"\"\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "# инициилизируем объект для лемматизации\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize(sentence):\n",
    "    \"\"\"Функция для токенизации строки текста, нахождения POS-тег для каждого токена и объединения в понятный формат для WordNet\"\"\"\n",
    "    #берем строку текста, токенизируем и выделяем POS-тег для каждого токена\n",
    "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "\n",
    " \n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #если доступного тега нет, добавляем токен как есть.\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #или добавляем тег для лемматизации токена\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    #объединяем лемматизированную строку текста с POS-тегами или без них\n",
    "    lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "\n",
    "    return(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим функцию, которая позволит добавлять индикаторы прогресса к операциям pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#применяем возможность добавления индикаторов прогресса к pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функцию для очистки текста: удаление лишних символов, лишних пробелов и приведение всех слов к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 159292/159292 [00:04<00:00, 39336.43it/s]\n"
     ]
    }
   ],
   "source": [
    "data_main['lemm_text']=data_main['text'].progress_apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функцию для лемматизации всего корпуса очищенного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 159292/159292 [16:28<00:00, 161.13it/s]\n"
     ]
    }
   ],
   "source": [
    "data_main['lemm_text']=data_main['lemm_text'].progress_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим получившиеся значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not try to edit war it s ju...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_main.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Весь корпус текста лемматизирован, очищен от лишних символов и стоп-слов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Деление датасета на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим датасет на тренировочную и тестовую выборки в пропорции 75 на 25. Для сохранения пропорций разных групп в целевом признаке укажем параметр `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_main['lemm_text'],\n",
    "        data_main['toxic'],\n",
    "        test_size = TEST_SIZE, \n",
    "        random_state = RANDOM_STATE,\n",
    "        stratify=data_main['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Созданы тренировочная и тестовая выборки с лемматизированным текстом, очищенным от лишних символов и стоп-слов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание признаков при помощи TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующим шагом нам необходимо создать счетчик для вычисления TF-IDF, передав ему множество стоп-слов на английском языке. Для того, чтобы в модели не были учтены частоты слов из тестовой выборки, то `fit_transform` применим к обучающей выборке, а `transform` к тестовой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим множество стоп-слов\n",
    "stopwords = list(set(nltk_stopwords.words('english')))\n",
    "\n",
    "#создадим счётчик, указав в нём стоп-слова:\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посчитаем частоты TF-IDF для тренировочной и тестовой выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_idf = count_tf_idf.fit_transform(X_train)\n",
    "X_test_tf_idf = count_tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим размерности полученных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469, 131387)\n",
      "(39823, 131387)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tf_idf.shape)\n",
    "print(X_test_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Признаки на основе TF-IDF созданы**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание признаков при помощи мешка слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим счетчик и также передадим ему множество со стоп-словами, которые он не должен учитывать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передадим счетчику наш столбец с предварительно обработанным текстом. Счетчик выделит из корпуса уникальные слова и посчитает количество их в каждой строке столбца. Отдельные буквы счетчик не учитывает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = count_vect.fit_transform(X_train)\n",
    "X_test_bow = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим размерности полученных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469, 131387)\n",
      "(39823, 131387)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Признаки на основе мешка слов созданы**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание признаков при помощи N-грамм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим счетчик для N-грамм. Стоп-слова убирать не будем, так как их удаление может привести к потере важных контекстных связей. Укажем просчет для 2 слов в N-gramm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_n_gramm = CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передадим счетчику наш столбец с предварительно обработанным текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n_gramm = count_n_gramm.fit_transform(X_train)\n",
    "X_test_n_gramm = count_n_gramm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим размерности полученных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119469, 131387)\n",
      "(39823, 131387)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bow.shape)\n",
    "print(X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Признаки на основе N-gramm созданы**\n",
    "\n",
    "Приступим к обучению моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели LogisticRegression() на разных наборах признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как модели обучаются долго, то не будем использовать автоматизированный подбор с гиперапарметрами сразу для всех моделей в пайплайне. Будем обучать базовые модели и смотреть на изменение метрики. Сначала построим базовую модель LogisticRegression() для мешка слов, TF-IDF и N-gramm, после этого набор признаков, на котором получится наивысшая метрика при кросс-валидации на логистической регрессии используем для модели дерева решений и подберем гиперпараметры при помощи OptunaSearchCV() с небольшим числом итераций, посмотрев как отработает вообще эта модель при таком огромном количестве признаков, после этого обучим CatBoostClassifier() на стандартном наборе гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу первую базовую модель логистической регресии на мешке слов, помимо основной метрики глянем метрику ROC-AUC, чтобы посмотреть на качество работы модели в общем . Для отображения одновременно нескольких метрик вместо `cross_val_score` будем использовать `cross_validate`, передав ему словарь с созданными метриками через `make_scorer`, а для корректного расчета `roc_auc` укажем параметры `response_method='predict_proba'` и  `greater_is_better=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики при кросс-валидации у первой базовой модели LogisticRegression(), обученной на мешке слов\n",
      "F1_score: 0.7526\n",
      "ROC-AUC: 0.9523\n"
     ]
    }
   ],
   "source": [
    "model_lr_bow = LogisticRegression(max_iter=1000)\n",
    "\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score,\n",
    "                           response_method='predict_proba', \n",
    "                           greater_is_better=True)\n",
    "            }\n",
    "\n",
    "score_lr_bow = cross_validate(\n",
    "    model_lr_bow,\n",
    "    X_train_bow,\n",
    "    y_train,\n",
    "    scoring = scoring,\n",
    "    n_jobs= -1)\n",
    "\n",
    "print('Метрики при кросс-валидации у первой базовой модели LogisticRegression(), обученной на мешке слов')\n",
    "print(f'F1_score: {score_lr_bow[\"test_f1\"].mean():.4f}')\n",
    "print(f'ROC-AUC: {score_lr_bow[\"test_roc_auc\"].mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить метрику F1, обучив нашу базовую модель на частотных признаках TF-IDF, для сравнения будем смотреть только основную метрику F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1_score при кросс-валидации у базовой модели LogisticRegression(), обученной на TF-IDF: 0.7171\n"
     ]
    }
   ],
   "source": [
    "model_lr_tf_idf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "score_lr_tf_idf = cross_val_score(\n",
    "    model_lr_tf_idf,\n",
    "    X_train_tf_idf,\n",
    "    y_train,\n",
    "    scoring = 'f1').mean()\n",
    "\n",
    "print(f'Метрика F1_score при кросс-валидации у базовой модели LogisticRegression(), обученной на TF-IDF: {score_lr_tf_idf:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика получилась ниже, чем у модели, обученной на мешке слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим нашу базовую модель логистической регресии на N-gramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1_score при кросс-валидации у базовой модели LogisticRegression(), обученной на N-gramm: 0.5948\n"
     ]
    }
   ],
   "source": [
    "model_lr_n_gramm = LogisticRegression(max_iter=1000)\n",
    "\n",
    "score_lr_n_gramm = cross_val_score(\n",
    "    model_lr_n_gramm,\n",
    "    X_train_n_gramm,\n",
    "    y_train,\n",
    "    scoring = 'f1').mean()\n",
    "\n",
    "print(f'Метрика F1_score при кросс-валидации у базовой модели LogisticRegression(), обученной на N-gramm: {score_lr_n_gramm:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика F1 на N-gramm получилась еще более низкой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить метрику качества, подобрав гиперпараметры к нашей лучшей модели LogisticRegression(), обученной на мешке слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Характеристики при GridSearchCV\n",
      "Время подбора гиперпараметров для моделей: 305.14443254470825\n",
      "Лучшая модель и её параметры:\n",
      "\n",
      " LogisticRegression(C=3, max_iter=1000)\n",
      "Метрика F1 для лучшей модели, полученная при кросс-валидации: 0.761\n"
     ]
    }
   ],
   "source": [
    "# словарь для модели  LogisticRegression()\n",
    "param_grid = {  \n",
    "             'C': range(2,15),\n",
    "            'class_weight': ['balanced', None]\n",
    "            }\n",
    "\n",
    "model_lr_best = LogisticRegression(max_iter=1000, solver = 'lbfgs', penalty = 'l2')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model_lr_best, \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    scoring = 'f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "\n",
    "grid_search_quit_time = time.time() - start\n",
    "print('Характеристики при GridSearchCV')\n",
    "print(f'Время подбора гиперпараметров для моделей: {grid_search_quit_time}')\n",
    "\n",
    "\n",
    "print('Лучшая модель и её параметры:\\n\\n', grid_search.best_estimator_)\n",
    "print ('Метрика F1 для лучшей модели, полученная при кросс-валидации:', round(grid_search.best_score_,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Благодаря подбору гиперпараметра `C=3` удалось немного улучшить метрику F1 модели LogisticRegression() до 0.761**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На первом этапе обучения моделей были получены следующие результаты:**\n",
    "- созданы разные наборы признаков на основе мешка слов, TF-IDF и N-gramm\n",
    "- были обучены несколько базовых моделей LogisticRegression() на разных данных, метрики качества F1 получились следующие:\n",
    "   - Мешок слов - 0.7522 ( при этом ROC-AUC составил 0.9523)\n",
    "   - TF-IDF - 0.7171\n",
    "   - N-gramm - 0.5947\n",
    "- при подборе гиперпараметров модель ***LogisticRegression(C=3, class_weight=None, max_iter=1000, solver = 'lbfgs', penalty = 'l2')*** улучшила метрику F1 до 0.761. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Устранение дисбаланса и повторное обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить метрику лучшей модели. Данные, которые показали наибольшую метрику - это мешок слов, поэтому сделаем андерсемплинг тренировочной выборки при помощи RandomUnderSampler(), устранив большой дисбаланс классов и обучим заново модель LogisticRegression(). Подберем гиперпараметр `C` для модели LogisticRegression() при помощи GridSearchCV(). Для того, чтобы оценивание при кросс-валидации происходило корректно, будем использовать `pipeline` из библиотеки `imblearn` и семплирование будет в нем определенным шагом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Устранение дисбаланса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим pipeline, в котором RandomUnderSampler() будет шагом перед моделями. Гиперпараметр C подберем при помощи GridSearch() для модели LogisticRegression(). Обучать будем на наборе тренировочных данных, на которых модель LogisticRegression() показала наивысшую метрику из прошлого раздела - мешке слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обьявим семплер\n",
    "sampler = RandomUnderSampler(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим пайплайн и получим лучший набор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Характеристики при GridSearchCV\n",
      "Время подбора гиперпараметров для моделей: 702.3254988193512\n",
      "Лучшая модель и её параметры на тренировочном датасете:\n",
      "\n",
      " Pipeline(steps=[('sampling', RandomUnderSampler(random_state=42)),\n",
      "                ('models',\n",
      "                 <catboost.core.CatBoostClassifier object at 0x000001F61A0599D0>)])\n",
      "Метрика F1 для лучшей модели, полученная при кросс-валидации:\n",
      " 0.7174311291361695\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('sampling', RandomUnderSampler(random_state=RANDOM_STATE)),\n",
    "    ('models', LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid_samp = [\n",
    "    # словарь для модели LogisticRegression()\n",
    "    {\n",
    "        'models': [LogisticRegression(max_iter=1000, \n",
    "                                      solver = 'lbfgs', \n",
    "                                      penalty = 'l2')],\n",
    "        'models__C': range(3,14),\n",
    "        'models__class_weight' : [None]\n",
    "            },\n",
    "    #словарь для модели CatBoostClassifier()\n",
    "        {\n",
    "        'models': [CatBoostClassifier(verbose = 0, \n",
    "                                 iterations = 1000, \n",
    "                                 learning_rate=0.1, \n",
    "                                 eval_metric = 'F1', \n",
    "                                 random_seed = RANDOM_STATE)]\n",
    "    }\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "grid_samp = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid=param_grid_samp, \n",
    "    cv=5, \n",
    "    scoring= 'f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_samp.fit(X_train_bow, y_train) \n",
    "\n",
    "grid_search_time = time.time() - start\n",
    "print('\\n\\nХарактеристики при GridSearchCV')\n",
    "print(f'Время подбора гиперпараметров для моделей: {grid_search_time}')\n",
    "\n",
    "print('Лучшая модель и её параметры на тренировочном датасете:\\n\\n', grid_samp.best_estimator_)\n",
    "print('Метрика F1 для лучшей модели, полученная при кросс-валидации:\\n', grid_samp.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика намного ниже, чем у базовой модели LogisticRegression(). Взглянем на таблицу результатов для лучших моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>param_models</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x000001F67D1F8A70&gt;</td>\n",
       "      <td>0.717431</td>\n",
       "      <td>340.846026</td>\n",
       "      <td>0.950456</td>\n",
       "      <td>{'models': &lt;catboost.core.CatBoostClassifier object at 0x000001F67D1F8A70&gt;}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.668357</td>\n",
       "      <td>10.467639</td>\n",
       "      <td>0.054180</td>\n",
       "      <td>{'models': LogisticRegression(max_iter=1000), 'models__C': 3, 'models__class_weight': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.665777</td>\n",
       "      <td>11.078612</td>\n",
       "      <td>0.052358</td>\n",
       "      <td>{'models': LogisticRegression(max_iter=1000), 'models__C': 4, 'models__class_weight': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.663194</td>\n",
       "      <td>12.895667</td>\n",
       "      <td>0.049964</td>\n",
       "      <td>{'models': LogisticRegression(max_iter=1000), 'models__C': 5, 'models__class_weight': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.661509</td>\n",
       "      <td>12.922465</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>{'models': LogisticRegression(max_iter=1000), 'models__C': 6, 'models__class_weight': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.659240</td>\n",
       "      <td>11.287034</td>\n",
       "      <td>0.053934</td>\n",
       "      <td>{'models': LogisticRegression(max_iter=1000), 'models__C': 7, 'models__class_weight': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.657477</td>\n",
       "      <td>12.895392</td>\n",
       "      <td>0.053604</td>\n",
       "      <td>{'models': LogisticRegression(max_iter=1000), 'models__C': 8, 'models__class_weight': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.656968</td>\n",
       "      <td>12.778675</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>{'models': LogisticRegression(max_iter=1000), 'models__C': 9, 'models__class_weight': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.655345</td>\n",
       "      <td>12.443288</td>\n",
       "      <td>0.049402</td>\n",
       "      <td>{'models': LogisticRegression(max_iter=1000), 'models__C': 10, 'models__class_weight': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression(max_iter=1000)</td>\n",
       "      <td>0.654512</td>\n",
       "      <td>11.293372</td>\n",
       "      <td>0.064078</td>\n",
       "      <td>{'models': LogisticRegression(max_iter=1000), 'models__C': 11, 'models__class_weight': None}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  \\\n",
       "11                1   \n",
       "0                 2   \n",
       "1                 3   \n",
       "2                 4   \n",
       "3                 5   \n",
       "4                 6   \n",
       "5                 7   \n",
       "6                 8   \n",
       "7                 9   \n",
       "8                10   \n",
       "\n",
       "                                                       param_models  \\\n",
       "11  <catboost.core.CatBoostClassifier object at 0x000001F67D1F8A70>   \n",
       "0                                 LogisticRegression(max_iter=1000)   \n",
       "1                                 LogisticRegression(max_iter=1000)   \n",
       "2                                 LogisticRegression(max_iter=1000)   \n",
       "3                                 LogisticRegression(max_iter=1000)   \n",
       "4                                 LogisticRegression(max_iter=1000)   \n",
       "5                                 LogisticRegression(max_iter=1000)   \n",
       "6                                 LogisticRegression(max_iter=1000)   \n",
       "7                                 LogisticRegression(max_iter=1000)   \n",
       "8                                 LogisticRegression(max_iter=1000)   \n",
       "\n",
       "    mean_test_score  mean_fit_time  mean_score_time  \\\n",
       "11         0.717431     340.846026         0.950456   \n",
       "0          0.668357      10.467639         0.054180   \n",
       "1          0.665777      11.078612         0.052358   \n",
       "2          0.663194      12.895667         0.049964   \n",
       "3          0.661509      12.922465         0.050746   \n",
       "4          0.659240      11.287034         0.053934   \n",
       "5          0.657477      12.895392         0.053604   \n",
       "6          0.656968      12.778675         0.054131   \n",
       "7          0.655345      12.443288         0.049402   \n",
       "8          0.654512      11.293372         0.064078   \n",
       "\n",
       "                                                                                          params  \n",
       "11                   {'models': <catboost.core.CatBoostClassifier object at 0x000001F67D1F8A70>}  \n",
       "0    {'models': LogisticRegression(max_iter=1000), 'models__C': 3, 'models__class_weight': None}  \n",
       "1    {'models': LogisticRegression(max_iter=1000), 'models__C': 4, 'models__class_weight': None}  \n",
       "2    {'models': LogisticRegression(max_iter=1000), 'models__C': 5, 'models__class_weight': None}  \n",
       "3    {'models': LogisticRegression(max_iter=1000), 'models__C': 6, 'models__class_weight': None}  \n",
       "4    {'models': LogisticRegression(max_iter=1000), 'models__C': 7, 'models__class_weight': None}  \n",
       "5    {'models': LogisticRegression(max_iter=1000), 'models__C': 8, 'models__class_weight': None}  \n",
       "6    {'models': LogisticRegression(max_iter=1000), 'models__C': 9, 'models__class_weight': None}  \n",
       "7   {'models': LogisticRegression(max_iter=1000), 'models__C': 10, 'models__class_weight': None}  \n",
       "8   {'models': LogisticRegression(max_iter=1000), 'models__C': 11, 'models__class_weight': None}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#устанавливаем настройки, чтобы таблица с результатами отображалась полностью\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#получаем таблицу с работой всех моделей\n",
    "result_models_rate = pd.DataFrame(grid_samp.cv_results_).sort_values(by = 'rank_test_score')\n",
    "\n",
    "#отображаем нужные столбцы и выводим для наглядности первые 5 лучших моделей\n",
    "display(result_models_rate[\n",
    "    ['rank_test_score', 'param_models','mean_test_score','mean_fit_time', 'mean_score_time','params']\n",
    "                        ].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Андерсемплинг тренировочной выборки не принес повышение метрики F1***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве эксперимента обучим модель DecisionTreeClassifier() и подберем гиперпараметры при помощи OptunaSearchCV(), кол-во итераций поставим небольшое - 120, чтобы не ждать слишком долго. Так как андерсемплинг не принес улучшение метрик у других моделей, а Optuna не работает в pipeline, чтобы метрика при кросс-валидации считалась корректно, будем обучать модель на всей тренировочной выборке на мешке слов, так как у базовой модели был получен наилучший результат метрики на этом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время поиска:220.06256437301636\n",
      "\n",
      "Лучший набор гиперпараметров: {'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 11}\n",
      "\n",
      "Метрика F1 при кросс-валидации у лучшей модели  DecisionTreeClassifier() составила 0.0050847\n"
     ]
    }
   ],
   "source": [
    "#отключение уведомлений от Optuna о ходе выполнения работы, оставляем только уведомления о критических ошибках\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"optuna\").setLevel(logging.ERROR)\n",
    "\n",
    "# запускаем таймер\n",
    "start = time.time()\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': distributions.IntDistribution(2, 16),\n",
    "    'min_samples_split': distributions.IntDistribution(2,12),\n",
    "    'min_samples_leaf': distributions.IntDistribution(1, 12),\n",
    "    'max_features': distributions.IntDistribution(1, 12)\n",
    "}\n",
    "\n",
    "oscv = OptunaSearchCV(\n",
    "        DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "        parameters,\n",
    "        cv=5,\n",
    "        scoring='f1',\n",
    "        n_trials = 120,\n",
    "        random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# поиск гиперпараметров\n",
    "oscv = oscv.fit(X_train_bow,y_train)\n",
    "\n",
    "\n",
    "# считаем, сколько секунд прошло с начала запуска\n",
    "oscv_search_time = time.time() - start\n",
    "print(f'Время поиска:{oscv_search_time}')\n",
    "\n",
    "#лучшие гиперпараметры\n",
    "print('\\nЛучший набор гиперпараметров:', oscv.best_params_)\n",
    "#лучшая метрика качества\n",
    "print(f'\\nМетрика F1 при кросс-валидации у лучшей модели  DecisionTreeClassifier() составила {oscv.best_score_:.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Из-за большого количества признаков (более 120 000) и относительно малого числа итераций метрика дерева решений составила всего 0.005**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добавить в наш итоговый пайплайн первым этапом векторизацию выборок, чтобы избежать утечки данных при обучении и получить более корректный результат при подсчете метрики кросс-валидацией. При векторизации выборок мы обучали CountVectorizer() на тренировочной выборке, а трансформировали и тренировочную и тестовую. Если при кросс-валидации тренировочная выборка разделится на несколько фолдов (4 фолда тренировочные и 1 валидационный в нашем случае), а CountVectorizer() уже обучался на всей тренировочной выборке изначальной, то у нас получается, что при кросс-валидации созданные валидационные фолды уже частично «засвечены» словарём, который формировался с их участием, что приводит к утечке данных. Поэтому нужно в пайплайне сделать отдельный шаг по векторизации, чтобы при делении на фолды при кросс-валидации CountVectorizer() обучался только на тренировочных фолдах при делении тренировочной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Характеристики при GridSearchCV\n",
      "Время подбора гиперпараметров для моделей: 1277.3582141399384\n",
      "Лучшая модель и её параметры на тренировочном датасете:\n",
      "\n",
      " Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(stop_words=['shouldn', 'wasn', \"haven't\",\n",
      "                                             \"you'll\", \"hadn't\", 'few', 'hadn',\n",
      "                                             'isn', 'that', 'their', 'haven',\n",
      "                                             'my', 'when', 'any', \"won't\",\n",
      "                                             \"shan't\", 'd', \"weren't\",\n",
      "                                             'themselves', 'because', 'yours',\n",
      "                                             'ain', 'down', 'during', \"you've\",\n",
      "                                             'shan', 'do', 'nor', 'against',\n",
      "                                             'our', ...])),\n",
      "                ('models',\n",
      "                 LogisticRegression(C=3, class_weight='balanced',\n",
      "                                    max_iter=1000))])\n",
      "Метрика F1 для лучшей модели, полученная при кросс-валидации:\n",
      " 0.7510143410551471\n"
     ]
    }
   ],
   "source": [
    "pipeline_all = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=stopwords)),\n",
    "    ('models', LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid_all = [\n",
    "    # словарь для модели LogisticRegression()\n",
    "    {\n",
    "        'models': [LogisticRegression(max_iter=1000, \n",
    "                                      solver = 'lbfgs', \n",
    "                                      penalty = 'l2')],\n",
    "        'models__C': range(3,14),\n",
    "        'models__class_weight' : ['balanced','None']\n",
    "            },\n",
    "    #словарь для модели CatBoostClassifier()\n",
    "        {\n",
    "        'models': [CatBoostClassifier(verbose = 0, \n",
    "                                 iterations = 1000, \n",
    "                                 learning_rate=0.1, \n",
    "                                 eval_metric = 'F1', \n",
    "                                 random_seed = RANDOM_STATE)]\n",
    "    }\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "grid_all = GridSearchCV(\n",
    "    pipeline_all, \n",
    "    param_grid=param_grid_all, \n",
    "    cv=5, \n",
    "    scoring= 'f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#используем просто очищенные данные и лемматизированные, но которые еще на векторизовались и не семплировались\n",
    "grid_all.fit(X_train, y_train) \n",
    "\n",
    "grid_search_time = time.time() - start\n",
    "print('\\n\\nХарактеристики при GridSearchCV')\n",
    "print(f'Время подбора гиперпараметров для моделей: {grid_search_time}')\n",
    "\n",
    "print('Лучшая модель и её параметры на тренировочном датасете:\\n\\n', grid_all.best_estimator_)\n",
    "print('Метрика F1 для лучшей модели, полученная при кросс-валидации:\\n', grid_all.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метрика F1 теперь считается более корректно и стала немного меньше, чем когда мы считали метрику и делали подбор гиперпараметров при помощи кросс-валидации, но использовали сразу подготовленные данные.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На первом этапе обучения моделей были получены следующие результаты:**\n",
    "- данные были вручную лемматизированы, убраны лишние знаки и отфильтрованы стоп-слова\n",
    "- в результате создания частотных признаков TF-IDF, мешка слов и N-gramm получилось 142384 столбца для каждого созданного набора признаков\n",
    "- базовая модель LogisticRegression() показала метрику F1 при кросс-валидации на:\n",
    "   - мешке слов - 0.76\n",
    "   - TF-IDF - 0.71\n",
    "   - N-gramm - 0.57\n",
    "- при подборе гиперпараметров для улучшения метрики модель ***LogisticRegression() (C=3, class_weight=None, max_iter=1000, solver = 'lbfgs', penalty = 'l2')*** улучшила метрику F1 до 0.761 на мешке слов.\n",
    "- лучшим набором признаков при работе базовой модели LogisticRegression() оказался мешок слов, поэтому для улучшения метрики в этом наборе был проведен андерсемплинг на тренировочной выборке и устранен дисбаланс классов. Также был составлен pipeline, включающий шаг по семплированию для корректной оценки метрики и заново обучена модель LogisticRegression() и модель CatBoostClassifier(). Метрика F1 на мешке слов после устранения дисбаланса оказалась ниже у всех моделей, чем при обучении на полном наборе данных.\n",
    "- в качестве эксперимента также была обучена модель DecisionTreeClassifier() и подобраны гиперпараметры при помощи OptunaSearchCV(), из-за большого количества входнных признаков эта модель не смогла показать приемлимый результат и метрика F1 составила всего 0.005.\n",
    "- также был составлен еще один ***пайплайн, включающий векторизацию при помощи  CountVectorizer()*** отдельным шагом для более корректной оценки метрики F1 и предотвращения утечки данных. Модель с подобранными гиперпараметрами ***LogisticRegression(C=3, class_weight='balanced',  max_iter=1000*** показала метрику F1 немного меньше, чем когда векторизация тренировочной выборки происходила до использования пайплайна, и составила 0.751. Так как это наиболее корректная оценки метрики F1, то за лучшую модель первого этапа обучения возьмем именно эту модель.\n",
    "\n",
    "\n",
    "\n",
    "Теперь попробуем улучшить метрику и обучить модели на эмбеддингах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторные представления BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявляем токенизатор BERT, предобученный на английских токсичных текстах в онлайн-сообществах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализация токенизатора модели Bert\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('unitary/toxic-bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим токенизацию к каждой строке столбца `text`, после найдем самую длинную строку с текстом и добавим во все остальные строки 0 в конце строки для того, что бы все строки сравнялись по длине, так как модель BERT работает только так. Также создадим матрицу-маску `attention_mask`, чтобы явно указать при создании эмбеддингов какие значения модели считать неважными (все добавленные нули в конце строк для увеличения длины до самой длинной строки в корпусе текста). Добавим параметры `max_length=150`, `truncation=True`, чтобы строки обрезались до максимальной указанной нами длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#применяем токенизатор и лематизатор к каждой строке текста\n",
    "tokenized = data_main['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, max_length=150, \n",
    "                               truncation=True, \n",
    "                               add_special_tokens=True))\n",
    "\n",
    "#находим самую длиннную строку с текстом, чтобы во все остальные строки с текстом добавить 0 справа до одинаковой длины\n",
    "#так как модель BERT сможет работать только со строками одинаковой длины\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "#в каждую токенизированную и лематизированную строку с текстом добавляем нули в конце и увеличиваем каждый массив (строку) до самой длинной строки\n",
    "#благодаря np.array, в следующей команде можно использовать np.where без циклов и лямбда функций сразу одной командой\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "#создаем маску для этого корпуса текста - даем модели понять, где искусственно добавленны нули и такие слова нужно пропускать\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем доступность GPU для расчета эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступность GPU: cuda\n"
     ]
    }
   ],
   "source": [
    "print('Доступность GPU:', torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявляем предобученную модель для создания эмбеддингов и расчеты переключаем на `cuda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert = transformers.BertModel.from_pretrained('unitary/toxic-bert').to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем процесс по созданию эмбеддингов на батчи по 150 строк, для того, чтобы не перегрузить компьютер слишком большим объемом, который будет занят в оперативной памяти и расчитаем эмбеддинги. Для того, чтобы модель быстрее сработала, укажем `with torch.no_grad()`, чтобы не считался градиент. При создании тензоров укажем .to('cuda'), а для дальнейшей обработки массива с эмбендингами передадим их обратно на cpu, так как gpu не умеет работать с массивами numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1061/1061 [11:13<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "#разобъем создание всех эмбеддингов на части - батчи, чтобы хватило оперативной памяти, потом в самом конце снова соединим вместе все части\n",
    "batch_size = 150\n",
    "\n",
    "#пустой список для записи туда на каждой итерации части эмбедингов, которые получаются за один батч\n",
    "embeddings = []\n",
    "\n",
    "#тут делается 2 задачи: 1- функция tqdm просто добавляется перед range, чтобы отображать выполнение каждой итерации цикла\n",
    "#2 - кол-во строк в корпусе целочисленно с округлением до нижнего целого значения делится на размер батча\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "\n",
    "#первые 150 строк (размер батча) превращаем в тензоры \n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).to('cuda') \n",
    "\n",
    "#тоже самое делаем для маски\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to('cuda')\n",
    "\n",
    "#с помощью этой строки ускоряем вычисление, в библиотеке torch указываем, что градиенты не нужны: модель BERT обучать не будем.        \n",
    "    with torch.no_grad():\n",
    "\n",
    "#получаем эмбеддинги для первых 150 строк, для первого батча, передавая в модель BERT готовые тензоры строк и тензоры масок\n",
    "        batch_embeddings = model_bert(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "#добавляем в наш список с эмбеддингами первые 150 эмбеддингов и передаем их обратно в gpu\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим все массивы в один и получим итоговые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#объединение всех массивов в один общий\n",
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим размерность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159150, 768)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим на тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиение данных для обучения модели\n",
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(\n",
    "        features,\n",
    "        data_main['toxic'][:159150],\n",
    "        test_size = TEST_SIZE,\n",
    "        random_state = RANDOM_STATE,\n",
    "        stratify=data_main['toxic'][:159150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим базовую модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики при кросс-валидации у модели LogisticRegression(), обученной на эмбеддингах после андерсемплинга\n",
      "F1_score: 0.9418\n",
      "ROC-AUC: 0.9971\n"
     ]
    }
   ],
   "source": [
    "model_lr_bert = LogisticRegression(max_iter=1000)\n",
    "\n",
    "score_lr_bert = cross_validate(\n",
    "    model_lr_bert,\n",
    "    X_train_bert,\n",
    "    y_train_bert,\n",
    "    scoring = scoring,\n",
    "    n_jobs= -1)\n",
    "\n",
    "print('Метрики при кросс-валидации у модели LogisticRegression(), обученной на эмбеддингах после андерсемплинга')\n",
    "print(f'F1_score: {score_lr_bert[\"test_f1\"].mean():.4f}')\n",
    "print(f'ROC-AUC: {score_lr_bert[\"test_roc_auc\"].mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метрика при кросс-валидации получилась намного выше, чем у моделей LogisticRegression() и CatBoostClassifier(), обученных на мешке слов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем также обучить модель CatBoostClassifier() на эмбеддингах, метрику посмотрим также при кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики при кросс-валидации у модели  CatBoostClassifier(), обученной на эмбеддингах после андерсемплинга\n",
      "F1_score: 0.9391\n",
      "ROC-AUC: 0.9965\n",
      "CPU times: total: 3.7 s\n",
      "Wall time: 7min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_cat_bert = CatBoostClassifier(learning_rate=0.1, iterations=1000, early_stopping_rounds=10, depth = 6,\n",
    "    eval_metric = 'F1')\n",
    "\n",
    "score_cat_bert = cross_validate(\n",
    "    model_cat_bert,\n",
    "    X_train_bert,\n",
    "    y_train_bert,\n",
    "    scoring = scoring,\n",
    "    n_jobs= -1)\n",
    "\n",
    "print('Метрики при кросс-валидации у модели  CatBoostClassifier(), обученной на эмбеддингах после андерсемплинга')\n",
    "print(f'F1_score: {score_cat_bert[\"test_f1\"].mean():.4f}')\n",
    "print(f'ROC-AUC: {score_cat_bert[\"test_roc_auc\"].mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метрика модели CatBoostClassifier() оказалась немного хуже, чем у модели LogisticRegression().**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На втором этапе обучения моделей на эмбеддингах были получены следующие результаты:**\n",
    "- вся тренировочная выборка с необработанным текстом была токенизирована, обработана и переведена в эмбеддинги при помощи инструментов модели BERT. При этом максимальная длина строки при токенизации была ограничена до 150 в силу вычислительных мощностей и объема оперативной памяти. Расчеты производились на gpu. При повторном обучении моделей метрика F1 при кросс-валидации получилась следующей:\n",
    "   - LogisticRegression(): 0.9418\n",
    "   - CatBoostClassifier(): 0.9391"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Учитывая полученные результаты, в качестве лучшей модели для тестирования будем использовать модель LogisticRegression(), обученную на эмбеддингах***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем тестирование лучшей модели LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1-score на тестовой выборке: 0.938\n"
     ]
    }
   ],
   "source": [
    "model_lr_bert = LogisticRegression(max_iter=1000)\n",
    "\n",
    "#обучаем модель на эмбеддингах\n",
    "model_lr_bert.fit(X_train_bert,y_train_bert)\n",
    "\n",
    "#делаем предсказание\n",
    "y_pred = model_lr_bert.predict(X_test_bert)\n",
    "score_best = f1_score(y_test_bert, y_pred)\n",
    "print(f'Метрика F1-score на тестовой выборке: {round(score_best,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним показатели с моделью DummyClassifier(), обученной на всем наборе данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявим модель `DummyClassifier`, обучим ее на данных и получим метрику `F1` для тестовой выборки. Так как константная модель просто присвает всем объектам метки на основе стратегии, примененной к целевому признаку, то данные для ее обучения подготоваливать нет необходимости. В параметре `strategy` укажем стратегию `uniform` для предсказания классов случайным образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1-score на тестовой выборке: 0.172\n"
     ]
    }
   ],
   "source": [
    "#инициилизируем модель DummyClassifier\n",
    "dummy_model = DummyClassifier(random_state=RANDOM_STATE,strategy='uniform')\n",
    "dummy_model.fit(X_train_bert, y_train_bert)\n",
    "\n",
    "#оценка константной модели\n",
    "print(f'Метрика F1-score на тестовой выборке: {round(f1_score(y_test_bert, dummy_model.predict(X_test_bert)),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Модель прошла проверку на адекватность и показала значение метрики выше, чем у константной модели DummyClassifier()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В результате исследования были проделаны следующие действия и получены следующие результаты:**\n",
    "    \n",
    "- ***на этапе предварительной подготовки*** были установлены и загружены необходимые библиотеки, создан основной датафрейм с данными\n",
    "    \n",
    "- ***на этапе предобработки данных***:\n",
    "  - проверено, что в датасете отсутствуют явные пропуски\n",
    "  - проверено наличие явных дубликатов\n",
    "  - из-за пропущенных индексов были обновлены индексы всего датасета\n",
    "  - выявлен сильный дисбаланс классов в целевом признаке\n",
    "\n",
    "- ***на первом этапе обучения моделей были получены следующие результаты:***\n",
    "  - данные были вручную лемматизированы, убраны лишние знаки и отфильтрованы стоп-слова\n",
    "  - в результате создания частотных признаков TF-IDF, мешка слов и N-gramm получилось 142384 столбца для каждого созданного набора признаков\n",
    "  - базовая модель LogisticRegression() показала метрику F1 при кросс-валидации на:\n",
    "     - мешке слов - 0.76\n",
    "     - TF-IDF - 0.71\n",
    "     - N-gramm - 0.57\n",
    "  - при подборе гиперпараметров для улучшения метрики модель ***LogisticRegression() (C=3, class_weight=None, max_iter=1000, solver = 'lbfgs', penalty = 'l2')*** улучшила метрику F1 до 0.761 на мешке слов.\n",
    "  - лучшим набором признаков при работе базовой модели LogisticRegression() оказался мешок слов, поэтому для улучшения метрики в этом наборе был проведен андерсемплинг на тренировочной выборке и устранен дисбаланс классов. Также был составлен pipeline, включающий шаг по семплированию для корректной оценки метрики и заново обучена модель LogisticRegression() и модель CatBoostClassifier(). Метрика F1 на мешке слов после устранения дисбаланса оказалась ниже у всех моделей, чем при обучении на полном наборе данных.\n",
    "  - в качестве эксперимента также была обучена модель DecisionTreeClassifier() и подобраны гиперпараметры при помощи OptunaSearchCV(), из-за большого количества входнных признаков эта модель не смогла показать приемлимый результат и метрика F1 составила всего 0.005.\n",
    "  - также был состален еще один ***пайплайн, включающий векторизацию при помощи  CountVectorizer()*** отдельным шагом для более корректной оценки метрики F1 и предотвращения утечки данных. Модель с подобранными гиперпараметрами ***LogisticRegression(C=3, class_weight='balanced', max_iter=1000)*** показала метрику F1 немного меньше, чем когда векторизация тренировочной выборки происходила до использования пайплайна, и составила 0.751. Так как это наиболее корректная оценки метрики F1, то за лучшую модель первого этапа обучения возьмем именно эту модель.\n",
    "- ***на втором этапе обучения моделей на эмбеддингах были получены следующие результаты:***\n",
    "  - вся тренировочная выборка с необработанным текстом была токенизирована, обработана и переведена в эмбеддинги при помощи инструментов модели BERT. При этом максимальная длина строки при токенизации была ограничена до 150 в силу вычислительных мощностей и объема оперативной памяти. Расчеты производились на gpu. При повторном обучении моделей метрика F1 при кросс-валидации получилась следующей:\n",
    "     - LogisticRegression(): 0.9418\n",
    "     - CatBoostClassifier(): 0.9391\n",
    "- ***на этапе тестрирования*** метрика F1 модели LogisticRegression() составила 0.938\n",
    "- ***также модель прошла проверку на адекватность и показала значение метрики выше, чем у константной модели DummyClassifier()***"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1366,
    "start_time": "2025-03-29T09:21:47.481Z"
   },
   {
    "duration": 23,
    "start_time": "2025-03-29T09:27:46.578Z"
   },
   {
    "duration": 115,
    "start_time": "2025-03-29T09:27:57.541Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T09:28:21.633Z"
   },
   {
    "duration": 609,
    "start_time": "2025-03-29T09:36:59.685Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T09:37:08.379Z"
   },
   {
    "duration": 6930,
    "start_time": "2025-03-29T10:58:12.932Z"
   },
   {
    "duration": 1416,
    "start_time": "2025-03-29T10:58:19.864Z"
   },
   {
    "duration": 84,
    "start_time": "2025-03-29T10:58:21.281Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T10:58:21.367Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T10:58:21.368Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T10:58:28.843Z"
   },
   {
    "duration": 934,
    "start_time": "2025-03-29T10:58:30.035Z"
   },
   {
    "duration": 922,
    "start_time": "2025-03-29T10:59:41.166Z"
   },
   {
    "duration": 942,
    "start_time": "2025-03-29T10:59:59.541Z"
   },
   {
    "duration": 32,
    "start_time": "2025-03-29T11:06:57.549Z"
   },
   {
    "duration": 230,
    "start_time": "2025-03-29T11:08:16.345Z"
   },
   {
    "duration": 749,
    "start_time": "2025-03-29T11:18:27.036Z"
   },
   {
    "duration": 210245,
    "start_time": "2025-03-29T11:18:51.183Z"
   },
   {
    "duration": 29,
    "start_time": "2025-03-29T11:22:43.763Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T11:22:53.617Z"
   },
   {
    "duration": 3335,
    "start_time": "2025-03-29T11:26:18.162Z"
   },
   {
    "duration": 2627,
    "start_time": "2025-03-29T11:26:59.728Z"
   },
   {
    "duration": 2281,
    "start_time": "2025-03-29T11:27:02.358Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T11:27:04.641Z"
   },
   {
    "duration": 1455,
    "start_time": "2025-03-29T11:27:04.646Z"
   },
   {
    "duration": 29,
    "start_time": "2025-03-29T11:27:06.103Z"
   },
   {
    "duration": 269,
    "start_time": "2025-03-29T11:27:06.134Z"
   },
   {
    "duration": 143,
    "start_time": "2025-03-29T11:27:06.404Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T11:27:06.549Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T11:27:06.550Z"
   },
   {
    "duration": 2988,
    "start_time": "2025-03-29T11:27:11.958Z"
   },
   {
    "duration": 2609,
    "start_time": "2025-03-29T11:28:20.352Z"
   },
   {
    "duration": 2371,
    "start_time": "2025-03-29T11:28:22.965Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T11:28:25.338Z"
   },
   {
    "duration": 1645,
    "start_time": "2025-03-29T11:28:25.342Z"
   },
   {
    "duration": 30,
    "start_time": "2025-03-29T11:28:26.990Z"
   },
   {
    "duration": 273,
    "start_time": "2025-03-29T11:28:27.021Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T11:28:27.296Z"
   },
   {
    "duration": 62,
    "start_time": "2025-03-29T11:29:04.416Z"
   },
   {
    "duration": 2562,
    "start_time": "2025-03-29T11:29:10.845Z"
   },
   {
    "duration": 2467,
    "start_time": "2025-03-29T11:29:13.410Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T11:29:15.879Z"
   },
   {
    "duration": 1372,
    "start_time": "2025-03-29T11:29:15.884Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-29T11:29:17.258Z"
   },
   {
    "duration": 302,
    "start_time": "2025-03-29T11:29:17.292Z"
   },
   {
    "duration": 98,
    "start_time": "2025-03-29T11:29:17.595Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T11:29:17.695Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T11:29:17.696Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T11:29:48.143Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-29T11:30:03.829Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-29T11:30:06.843Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T11:31:07.060Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-29T11:31:12.783Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-29T11:31:26.650Z"
   },
   {
    "duration": 27,
    "start_time": "2025-03-29T11:31:43.358Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-29T11:31:45.118Z"
   },
   {
    "duration": 2617,
    "start_time": "2025-03-29T11:32:55.682Z"
   },
   {
    "duration": 1370,
    "start_time": "2025-03-29T11:32:58.303Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T11:32:59.674Z"
   },
   {
    "duration": 1032,
    "start_time": "2025-03-29T11:32:59.679Z"
   },
   {
    "duration": 28,
    "start_time": "2025-03-29T11:33:00.714Z"
   },
   {
    "duration": 253,
    "start_time": "2025-03-29T11:33:00.743Z"
   },
   {
    "duration": 2477,
    "start_time": "2025-03-29T11:34:24.545Z"
   },
   {
    "duration": 2102,
    "start_time": "2025-03-29T11:34:27.025Z"
   },
   {
    "duration": 2,
    "start_time": "2025-03-29T11:34:29.129Z"
   },
   {
    "duration": 1269,
    "start_time": "2025-03-29T11:34:29.133Z"
   },
   {
    "duration": 30,
    "start_time": "2025-03-29T11:34:30.404Z"
   },
   {
    "duration": 295,
    "start_time": "2025-03-29T11:34:30.436Z"
   },
   {
    "duration": 686,
    "start_time": "2025-03-29T11:34:30.733Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T11:34:31.420Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T11:34:31.422Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T11:34:31.423Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T11:34:31.424Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T11:34:31.425Z"
   },
   {
    "duration": 29,
    "start_time": "2025-03-29T11:34:43.921Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T11:36:49.436Z"
   },
   {
    "duration": 70,
    "start_time": "2025-03-29T11:37:01.979Z"
   },
   {
    "duration": 78,
    "start_time": "2025-03-29T11:37:13.448Z"
   },
   {
    "duration": 52,
    "start_time": "2025-03-29T11:37:23.350Z"
   },
   {
    "duration": 48,
    "start_time": "2025-03-29T11:37:49.423Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-29T11:38:11.011Z"
   },
   {
    "duration": 41,
    "start_time": "2025-03-29T11:39:04.041Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-29T11:39:28.201Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-29T11:40:03.035Z"
   },
   {
    "duration": 371,
    "start_time": "2025-03-29T11:42:26.994Z"
   },
   {
    "duration": 50,
    "start_time": "2025-03-29T11:43:07.717Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-29T11:43:32.418Z"
   },
   {
    "duration": 43,
    "start_time": "2025-03-29T11:45:49.623Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-29T11:45:53.529Z"
   },
   {
    "duration": 48,
    "start_time": "2025-03-29T11:47:06.116Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T11:47:27.042Z"
   },
   {
    "duration": 56,
    "start_time": "2025-03-29T11:47:43.530Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-29T11:47:48.369Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T11:47:53.666Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T11:47:57.204Z"
   },
   {
    "duration": 741,
    "start_time": "2025-03-29T11:49:48.264Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T11:50:04.442Z"
   },
   {
    "duration": 111609,
    "start_time": "2025-03-29T11:51:15.727Z"
   },
   {
    "duration": 183617,
    "start_time": "2025-03-29T11:53:39.528Z"
   },
   {
    "duration": 20,
    "start_time": "2025-03-29T11:56:48.055Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T11:56:57.931Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T11:56:59.747Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-29T11:57:01.030Z"
   },
   {
    "duration": 38439,
    "start_time": "2025-03-29T11:57:34.401Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-29T11:58:19.571Z"
   },
   {
    "duration": 2469,
    "start_time": "2025-03-29T12:06:42.053Z"
   },
   {
    "duration": 1484,
    "start_time": "2025-03-29T12:06:44.525Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T12:06:46.010Z"
   },
   {
    "duration": 993,
    "start_time": "2025-03-29T12:06:46.014Z"
   },
   {
    "duration": 28,
    "start_time": "2025-03-29T12:06:47.010Z"
   },
   {
    "duration": 253,
    "start_time": "2025-03-29T12:06:47.040Z"
   },
   {
    "duration": 20,
    "start_time": "2025-03-29T12:06:47.294Z"
   },
   {
    "duration": 298125,
    "start_time": "2025-03-29T12:06:47.316Z"
   },
   {
    "duration": 174,
    "start_time": "2025-03-29T12:11:45.443Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-29T12:12:56.907Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T12:16:58.333Z"
   },
   {
    "duration": 33,
    "start_time": "2025-03-29T12:18:23.049Z"
   },
   {
    "duration": 28,
    "start_time": "2025-03-29T12:18:28.640Z"
   },
   {
    "duration": 46,
    "start_time": "2025-03-29T12:18:47.010Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T12:20:39.683Z"
   },
   {
    "duration": 50,
    "start_time": "2025-03-29T12:21:06.283Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T12:21:40.995Z"
   },
   {
    "duration": 74,
    "start_time": "2025-03-29T12:21:44.259Z"
   },
   {
    "duration": 38,
    "start_time": "2025-03-29T12:23:15.021Z"
   },
   {
    "duration": 21,
    "start_time": "2025-03-29T12:23:24.459Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T12:23:45.033Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T12:23:49.326Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T12:24:03.046Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T12:24:23.581Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-29T12:24:27.395Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T12:24:28.305Z"
   },
   {
    "duration": 20,
    "start_time": "2025-03-29T12:24:43.074Z"
   },
   {
    "duration": 445,
    "start_time": "2025-03-29T13:05:45.829Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T13:05:57.339Z"
   },
   {
    "duration": 360,
    "start_time": "2025-03-29T13:05:59.295Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T13:06:10.265Z"
   },
   {
    "duration": 1303,
    "start_time": "2025-03-29T13:06:12.108Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-29T13:08:41.959Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-29T13:09:13.159Z"
   },
   {
    "duration": 2411,
    "start_time": "2025-03-29T13:09:17.238Z"
   },
   {
    "duration": 1419,
    "start_time": "2025-03-29T13:09:19.652Z"
   },
   {
    "duration": 2,
    "start_time": "2025-03-29T13:09:21.073Z"
   },
   {
    "duration": 1032,
    "start_time": "2025-03-29T13:09:21.078Z"
   },
   {
    "duration": 28,
    "start_time": "2025-03-29T13:09:22.112Z"
   },
   {
    "duration": 243,
    "start_time": "2025-03-29T13:09:22.142Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T13:09:22.386Z"
   },
   {
    "duration": 136,
    "start_time": "2025-03-29T13:09:22.395Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:09:22.533Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:09:22.534Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:09:22.535Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:09:22.536Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:09:22.537Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:09:22.538Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:09:22.539Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:09:22.542Z"
   },
   {
    "duration": 233,
    "start_time": "2025-03-29T13:09:26.768Z"
   },
   {
    "duration": 5199,
    "start_time": "2025-03-29T13:09:40.586Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-29T13:09:53.064Z"
   },
   {
    "duration": 2424,
    "start_time": "2025-03-29T13:10:40.347Z"
   },
   {
    "duration": 2059,
    "start_time": "2025-03-29T13:10:42.774Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T13:10:44.835Z"
   },
   {
    "duration": 1278,
    "start_time": "2025-03-29T13:10:44.841Z"
   },
   {
    "duration": 28,
    "start_time": "2025-03-29T13:10:46.122Z"
   },
   {
    "duration": 246,
    "start_time": "2025-03-29T13:10:46.152Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T13:10:46.400Z"
   },
   {
    "duration": 150,
    "start_time": "2025-03-29T13:10:46.408Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:10:46.560Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:10:46.562Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:10:46.563Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:10:46.565Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:10:46.566Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:10:46.567Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:10:46.568Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:10:46.570Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T13:10:46.570Z"
   },
   {
    "duration": 340,
    "start_time": "2025-03-29T13:10:49.797Z"
   },
   {
    "duration": 5372,
    "start_time": "2025-03-29T13:10:50.585Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T13:11:13.801Z"
   },
   {
    "duration": 101,
    "start_time": "2025-03-29T13:11:22.846Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T13:12:38.100Z"
   },
   {
    "duration": 6554,
    "start_time": "2025-03-29T16:52:29.224Z"
   },
   {
    "duration": 1491,
    "start_time": "2025-03-29T16:52:35.781Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T16:52:37.274Z"
   },
   {
    "duration": 970,
    "start_time": "2025-03-29T16:52:37.278Z"
   },
   {
    "duration": 32,
    "start_time": "2025-03-29T16:52:38.250Z"
   },
   {
    "duration": 266,
    "start_time": "2025-03-29T16:52:38.283Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-29T16:52:38.551Z"
   },
   {
    "duration": 128,
    "start_time": "2025-03-29T16:52:38.563Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.693Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.694Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.695Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.696Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.697Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.698Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.699Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.700Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.700Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T16:52:38.702Z"
   },
   {
    "duration": 513,
    "start_time": "2025-03-29T16:55:30.437Z"
   },
   {
    "duration": 2,
    "start_time": "2025-03-29T16:55:55.051Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-29T16:55:57.792Z"
   },
   {
    "duration": 4846,
    "start_time": "2025-03-29T16:56:48.857Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-29T16:57:14.820Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T16:58:25.241Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T16:58:37.467Z"
   },
   {
    "duration": 5070,
    "start_time": "2025-03-29T16:58:48.991Z"
   },
   {
    "duration": 5336,
    "start_time": "2025-03-29T16:59:00.560Z"
   },
   {
    "duration": 6744,
    "start_time": "2025-03-29T16:59:26.869Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T16:59:43.255Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-29T17:00:11.101Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-29T17:00:20.537Z"
   },
   {
    "duration": 2600,
    "start_time": "2025-03-29T17:02:47.576Z"
   },
   {
    "duration": 2529,
    "start_time": "2025-03-29T17:02:50.180Z"
   },
   {
    "duration": 2,
    "start_time": "2025-03-29T17:02:52.711Z"
   },
   {
    "duration": 962,
    "start_time": "2025-03-29T17:02:52.716Z"
   },
   {
    "duration": 32,
    "start_time": "2025-03-29T17:02:53.680Z"
   },
   {
    "duration": 254,
    "start_time": "2025-03-29T17:02:53.714Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T17:02:53.969Z"
   },
   {
    "duration": 135,
    "start_time": "2025-03-29T17:02:53.976Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.113Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.114Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.115Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.116Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.117Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.119Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.120Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.122Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.123Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.125Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:02:54.125Z"
   },
   {
    "duration": 5101,
    "start_time": "2025-03-29T17:03:24.272Z"
   },
   {
    "duration": 158,
    "start_time": "2025-03-29T17:04:27.519Z"
   },
   {
    "duration": 5380,
    "start_time": "2025-03-29T17:04:32.220Z"
   },
   {
    "duration": 6830,
    "start_time": "2025-03-29T17:04:45.378Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-29T17:05:08.728Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T17:06:11.659Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-29T17:06:21.016Z"
   },
   {
    "duration": 2333,
    "start_time": "2025-03-29T17:08:30.496Z"
   },
   {
    "duration": 2260,
    "start_time": "2025-03-29T17:08:32.833Z"
   },
   {
    "duration": 2,
    "start_time": "2025-03-29T17:08:35.095Z"
   },
   {
    "duration": 971,
    "start_time": "2025-03-29T17:08:35.100Z"
   },
   {
    "duration": 27,
    "start_time": "2025-03-29T17:08:36.072Z"
   },
   {
    "duration": 230,
    "start_time": "2025-03-29T17:08:36.100Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T17:08:36.331Z"
   },
   {
    "duration": 156,
    "start_time": "2025-03-29T17:08:36.339Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:08:36.497Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:08:36.498Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:08:36.499Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:08:36.500Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:08:36.501Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:08:36.503Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T17:08:36.503Z"
   },
   {
    "duration": 5128,
    "start_time": "2025-03-29T17:08:40.997Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-29T17:08:50.702Z"
   },
   {
    "duration": 145,
    "start_time": "2025-03-29T17:08:56.785Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T17:09:08.161Z"
   },
   {
    "duration": 6830,
    "start_time": "2025-03-29T17:09:12.054Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T17:09:39.567Z"
   },
   {
    "duration": 23382,
    "start_time": "2025-03-29T17:09:52.975Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-29T17:10:59.989Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-29T17:11:25.025Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T17:11:28.096Z"
   },
   {
    "duration": 21,
    "start_time": "2025-03-29T17:12:13.468Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T17:12:13.890Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T17:13:04.411Z"
   },
   {
    "duration": 86756,
    "start_time": "2025-03-29T17:13:17.535Z"
   },
   {
    "duration": 636,
    "start_time": "2025-03-29T17:14:45.581Z"
   },
   {
    "duration": 643,
    "start_time": "2025-03-29T17:15:27.137Z"
   },
   {
    "duration": 2272343,
    "start_time": "2025-03-29T17:16:12.921Z"
   },
   {
    "duration": 554,
    "start_time": "2025-03-29T18:37:24.768Z"
   },
   {
    "duration": 568,
    "start_time": "2025-03-29T18:37:41.596Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-29T18:37:53.041Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-29T18:37:57.154Z"
   },
   {
    "duration": 83,
    "start_time": "2025-03-29T18:48:36.648Z"
   },
   {
    "duration": 342997,
    "start_time": "2025-03-29T18:48:39.954Z"
   },
   {
    "duration": 15712,
    "start_time": "2025-03-29T19:00:57.725Z"
   },
   {
    "duration": 14852,
    "start_time": "2025-03-29T19:12:22.157Z"
   },
   {
    "duration": 2,
    "start_time": "2025-03-29T19:12:53.209Z"
   },
   {
    "duration": 4470,
    "start_time": "2025-03-29T19:12:55.681Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T19:13:40.235Z"
   },
   {
    "duration": 4805,
    "start_time": "2025-03-29T19:13:41.808Z"
   },
   {
    "duration": 5161,
    "start_time": "2025-03-29T19:13:56.309Z"
   },
   {
    "duration": 2833,
    "start_time": "2025-03-29T19:16:03.208Z"
   },
   {
    "duration": 2200,
    "start_time": "2025-03-29T19:16:06.043Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T19:16:08.244Z"
   },
   {
    "duration": 1001,
    "start_time": "2025-03-29T19:16:08.249Z"
   },
   {
    "duration": 29,
    "start_time": "2025-03-29T19:16:09.256Z"
   },
   {
    "duration": 240,
    "start_time": "2025-03-29T19:16:09.287Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T19:16:09.529Z"
   },
   {
    "duration": 135,
    "start_time": "2025-03-29T19:16:09.536Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.673Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.674Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.675Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.676Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.677Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.678Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.679Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.680Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.681Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.682Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.683Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.684Z"
   },
   {
    "duration": 1,
    "start_time": "2025-03-29T19:16:09.684Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.686Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.687Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.688Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.689Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.690Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-29T19:16:09.691Z"
   },
   {
    "duration": 5272,
    "start_time": "2025-03-29T19:16:14.605Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-29T19:16:28.457Z"
   },
   {
    "duration": 149,
    "start_time": "2025-03-29T19:16:36.772Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-29T19:19:42.784Z"
   },
   {
    "duration": 7118,
    "start_time": "2025-03-29T19:19:53.067Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T19:20:02.416Z"
   },
   {
    "duration": 22580,
    "start_time": "2025-03-29T19:20:03.077Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T19:20:25.659Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-29T19:20:25.666Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T19:20:25.686Z"
   },
   {
    "duration": 7591,
    "start_time": "2025-03-29T19:20:42.077Z"
   },
   {
    "duration": 5557,
    "start_time": "2025-03-29T19:20:57.619Z"
   },
   {
    "duration": 4431,
    "start_time": "2025-03-29T19:21:26.792Z"
   },
   {
    "duration": 4905,
    "start_time": "2025-03-29T19:22:17.950Z"
   },
   {
    "duration": 4087,
    "start_time": "2025-03-29T19:22:32.049Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T19:22:50.885Z"
   },
   {
    "duration": 4580,
    "start_time": "2025-03-29T19:23:36.411Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T19:24:12.845Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T19:55:42.867Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T19:55:47.838Z"
   },
   {
    "duration": 5704,
    "start_time": "2025-03-29T19:56:41.546Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-29T19:57:46.174Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T19:57:46.763Z"
   },
   {
    "duration": 1135027,
    "start_time": "2025-03-29T19:57:52.770Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T20:18:28.730Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-29T20:18:38.934Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T20:18:46.549Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T20:19:30.369Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-29T20:19:38.825Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-29T20:19:52.153Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-29T20:19:55.635Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-29T20:20:11.240Z"
   },
   {
    "duration": 42,
    "start_time": "2025-03-29T20:20:40.564Z"
   },
   {
    "duration": 28,
    "start_time": "2025-03-29T20:20:46.994Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T20:21:10.662Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-29T20:21:16.818Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-29T20:21:22.855Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-29T20:21:39.680Z"
   },
   {
    "duration": 6496,
    "start_time": "2025-03-30T05:51:54.986Z"
   },
   {
    "duration": 1535,
    "start_time": "2025-03-30T05:52:01.485Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-30T05:52:03.021Z"
   },
   {
    "duration": 981,
    "start_time": "2025-03-30T05:52:03.026Z"
   },
   {
    "duration": 29,
    "start_time": "2025-03-30T05:52:04.008Z"
   },
   {
    "duration": 242,
    "start_time": "2025-03-30T05:52:04.039Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-30T05:52:04.282Z"
   },
   {
    "duration": 16,
    "start_time": "2025-03-30T05:52:04.291Z"
   },
   {
    "duration": 120,
    "start_time": "2025-03-30T05:52:04.309Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.431Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.432Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.433Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.434Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.435Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.436Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.437Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.438Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.439Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.440Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.441Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.443Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.443Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.445Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.445Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.447Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.448Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.449Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.451Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.452Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.454Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.455Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T05:52:04.456Z"
   },
   {
    "duration": 1,
    "start_time": "2025-03-30T05:52:04.457Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-30T05:52:23.661Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-30T05:53:03.736Z"
   },
   {
    "duration": 309069,
    "start_time": "2025-03-30T05:53:10.658Z"
   },
   {
    "duration": 21441,
    "start_time": "2025-03-30T05:58:41.538Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-30T05:59:34.375Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-30T05:59:34.867Z"
   },
   {
    "duration": 966235,
    "start_time": "2025-03-30T06:00:35.842Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-30T06:19:20.567Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-30T06:19:31.606Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-30T06:19:37.579Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-30T06:19:42.691Z"
   },
   {
    "duration": 23,
    "start_time": "2025-03-30T06:19:46.827Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-30T06:22:01.240Z"
   },
   {
    "duration": 3698,
    "start_time": "2025-03-30T06:24:41.880Z"
   },
   {
    "duration": 171871,
    "start_time": "2025-03-30T06:54:14.043Z"
   },
   {
    "duration": 700,
    "start_time": "2025-03-30T06:57:23.019Z"
   },
   {
    "duration": 240542,
    "start_time": "2025-03-30T06:59:49.291Z"
   },
   {
    "duration": 13824,
    "start_time": "2025-03-30T07:06:27.000Z"
   },
   {
    "duration": 44898,
    "start_time": "2025-03-30T07:06:47.100Z"
   },
   {
    "duration": 47,
    "start_time": "2025-03-30T07:16:49.955Z"
   },
   {
    "duration": 2770,
    "start_time": "2025-03-30T07:16:57.088Z"
   },
   {
    "duration": 3073,
    "start_time": "2025-03-30T07:16:59.860Z"
   },
   {
    "duration": 2,
    "start_time": "2025-03-30T07:17:02.935Z"
   },
   {
    "duration": 1036,
    "start_time": "2025-03-30T07:17:02.939Z"
   },
   {
    "duration": 37,
    "start_time": "2025-03-30T07:17:03.977Z"
   },
   {
    "duration": 240,
    "start_time": "2025-03-30T07:17:04.016Z"
   },
   {
    "duration": 9,
    "start_time": "2025-03-30T07:17:04.258Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-30T07:17:04.268Z"
   },
   {
    "duration": 131,
    "start_time": "2025-03-30T07:17:04.279Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.413Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.414Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.415Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.416Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.417Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.418Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.418Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.419Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.420Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.421Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.422Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.423Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.423Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.424Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.425Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.427Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.427Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.428Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.429Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.430Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.431Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.431Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.432Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.433Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.434Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.435Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.436Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.437Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-30T07:17:04.438Z"
   },
   {
    "duration": 21,
    "start_time": "2025-03-30T07:17:13.216Z"
   },
   {
    "duration": 9,
    "start_time": "2025-03-30T07:17:16.186Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-30T07:17:26.540Z"
   },
   {
    "duration": 9118,
    "start_time": "2025-03-30T07:17:33.617Z"
   },
   {
    "duration": 8269,
    "start_time": "2025-03-30T07:17:46.651Z"
   },
   {
    "duration": 28,
    "start_time": "2025-03-30T07:18:20.190Z"
   },
   {
    "duration": 1668,
    "start_time": "2025-03-30T07:18:38.115Z"
   },
   {
    "duration": 4857,
    "start_time": "2025-03-30T07:18:41.782Z"
   },
   {
    "duration": 84,
    "start_time": "2025-03-30T07:20:49.625Z"
   },
   {
    "duration": 266,
    "start_time": "2025-03-30T07:20:56.249Z"
   },
   {
    "duration": 19,
    "start_time": "2025-03-30T07:21:07.965Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-30T07:21:14.788Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
