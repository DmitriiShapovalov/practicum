# Классификация твитов

## Задача
Построение модели для классификации комментариев на позитивные и негативные.

## Описание работы
Интернет-магазин запускает новый сервис с возможностью дополнения и комментирования описания товаров самими клиентами. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

## Описание данных
В нашем распоряжении набор данных с разметкой о токсичности правок

## План работы
- Загрузка и подготовка данных разными подходами.
- Обучение разных моделей.
- Тестирование и проверка на адекватность. Метрика качества *F1* полученной модели должна быть не меньше 0.75. 
- Итоговые выводы.
 
## Используемые метрики
F1

## Используемые библиотеки
*transformers, nltk, tqdm, torch, imblearn, optuna, catboost, re, pandas, numpy, matplotlib, seaborn, time, requests, os, logging, warnings, sklearn*

## Итоговые выводы
- Данные загружены и выполнена их предобработка
- Текст очищен от лишних символов и стоп-слов, произведена лематизация текста, включающая добавление POS-тегов
- На первом этапе обучения было установлено, что обучение модели LogisticRegression() на созданных признаках при помощи мешка слов позволила достичь базовой метрики F1 = 0.761 при оптимизации гиперпараметров модели.
- Создание частотных признаков TF-IDF и N-грамм, а также устранение дисбаланса признаков, обучение других моделей (CatBoostClassifier() и DecisionTreeClassifier() и оптимизация их параметров, не привело к повышению итоговой метрики по сравнению с базовым подходом. 
- На втором этапе обучения применение BERT-эмбеддингов с ограничением длины до 150 токенов значительно улучшило качество моделей: CatBoostClassifier() улучшила метрику F1 до 0.9391 при кросс-валидации, а базовая модель LogisticRegression() улучшила метрику F1 до 0.9418 при кросс-валидации и стала лучшей моделью.
- Метрика F1 базовой модели LogisticRegression(), обученной на BERT-эмбеддингах при тестировании составила 0.938